# Locating Visual Explanation for Video Question Answering

## New Task: Video Question Answering with Visual Explanation (VQA-VE)
![Task](https://github.com/VQA-VE/VQA-VE/blob/master/task.jpg "VQA-VE")
*Figure 1. VQA-VE requires to provide visual explanation for predicted answers. There are advantages for visual explanation: (Left) visual explanation can serve as an evidence to justify the correctness of answers; (Middle) visual explanation can provide supplementary information for the content of QA pairs; (Right) visua lexplanation can give clear indication to elaborate the vague expression in QA pairs.*

We introduce a new task called Video QUestion Answering with Visual Explanation (VQA-VE), which requires to generate natural language sentences as answers and provide visual explanations (i.e., locating relevant moment within the whole video) simultaneously. As shown in Figure 1, a visual explanation can be taken as a nevidence to justify if predicted answers are convincible and traceable, or as a supplementary that provide relevant information on the context of QA pairs, or even as a spercification rthat indicatre vague expressions or abstract concepts in QA pairs vividly.

This task bridges two separate and typical visual tasks: video question answering and temporal localization, and also comes with its own set of challenges. 


## New Dataset: Activity-QA


## New Model


## New Metrics

## Experiments
